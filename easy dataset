# -*- coding: utf-8 -*-
"""final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gMgZMK13YgMSKPFRN5Yo_OQXoudw1dHy
"""

pip install easy-vqa

from easy_vqa import get_trainQuestions, get_testQuestions

trainQuestions, trainAnswers, train_image_ids = get_trainQuestions()
testQuestions, testAnswers, test_image_ids = get_testQuestions()
#taking a look at the questions,answers and their ids
print(trainQuestions[0]) 
print(trainAnswers[0])   
print(train_image_ids[0])

#checking image paths for both test and train 
from easy_vqa import get_train_image_paths, get_test_image_paths

train_image_paths = get_train_image_paths()
test_image_paths = get_test_image_paths()

print(train_image_paths[0])

from IPython.display import Image
Image(filename='/usr/local/lib/python3.7/dist-packages/easy_vqa/data/train/images/0.png')

Image(filename='/usr/local/lib/python3.7/dist-packages/easy_vqa/data/train/images/30.png')

pip install easy-vqa tensorflow Pillow numpy

#defining our models, both CNN and question network 
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Multiply
from tensorflow.keras.optimizers import Adam

def buildModel(imShape, vocabSize, numAnswers, bigModel):
  # The CNN
  input_img = Input(shape = imShape)
  a1 = Conv2D(8, 3, padding='same')(input_img)
  a1 = MaxPooling2D()(a1)
  a1 = Conv2D(16, 3, padding='same')(a1)
  a1 = MaxPooling2D()(a1)
  if bigModel:
    a1 = Conv2D(32, 3, padding='same')(a1)
    a1 = MaxPooling2D()(a1)
  a1 = Flatten()(a1)
  a1 = Dense(32, activation='tanh')(a1)

  # The question network
  q_input = Input(shape=(vocabSize,))
  a2 = Dense(32, activation='tanh')(q_input)
  a2 = Dense(32, activation='tanh')(a2)

  # Merge -> output
  out = Multiply()([a1, a2])
  out = Dense(32, activation='tanh')(out)
  out = Dense(numAnswers, activation='softmax')(out)

  model = Model(inputs=[input_img, q_input], outputs=out)
  model.compile(Adam(lr=5e-4), loss='categorical_crossentropy', metrics=['accuracy'])
  return model

#preprocessing 
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.utils import to_categorical
import json
import os
import numpy as np
from easy_vqa import get_trainQuestions, get_testQuestions, get_train_image_paths, get_test_image_paths, getAnswers

def setup(use_data_dir):
  print('\n--- Reading questions...')
  if use_data_dir:
    # Read data from data/ folder
    def readQuestions(path):
      with open(path, 'r') as file:
        qs = json.load(file)
      texts = [q[0] for q in qs]
      answers = [q[1] for q in qs]
      image_ids = [q[2] for q in qs]
      return (texts, answers, image_ids)
    trainQues, trainAnswers, train_image_ids = readQuestions('data/train/questions.json')
    testQues, testAnswers, test_image_ids = readQuestions('data/test/questions.json')
  else:
    # Use the easy-vqa package
    trainQues, trainAnswers, train_image_ids = get_trainQuestions()
    testQues, testAnswers, test_image_ids = get_testQuestions()
  print(f'Read {len(trainQues)} training questions and {len(testQues)} testing questions.')


  print('\n--- Reading answers...')
  if use_data_dir:
    # Read answers from data/ folder
    with open('data/answers.txt', 'r') as file:
      allAnswers = [a.strip() for a in file]
  else:
    # Read answers from the easy-vqa package
    allAnswers = getAnswers()
  numAnswers = len(allAnswers)
  print(f'Found {numAnswers} total answers:')
  print(allAnswers)


  print('\n--- Reading/processing images...')
  def load_and_proccess_image(image_path):
    # Load image, then scale and shift pixel values to [-0.5, 0.5]
    imge= img_to_array(load_img(image_path))
    return imge/ 255 - 0.5

  def read_Imges(paths):
    # paths is a dict mapping image ID to image path
    # Returns a dict mapping image ID to the processed image
    Images = {}
    for image_id, image_path in paths.items():
      Images[image_id] = load_and_proccess_image(image_path)
    return Images

  if use_data_dir:
    # Read images from data/ folder
    def extractPaths(dir):
      paths = {}
      for filename in os.listdir(dir):
        if filename.endswith('.png'):
          image_id = int(filename[:-4])
          paths[image_id] = os.path.join(dir, filename)
      return paths

    train_images = read_Imges(extractPaths('data/train/images'))
    test_images  = read_Imges(extractPaths('data/test/images'))
  else:
    # Read images from the easy-vqa package
    train_images = read_Imges(get_train_image_paths())
    test_images = read_Imges(get_test_image_paths())
  imShape = train_images[0].shape
  print(f'Read {len(train_images)} training images and {len(test_images)} testing images.')
  print(f'Each image has shape {imShape}.')


  print('\n--- Fitting question tokenizer...')
  tokenizer = Tokenizer()
  tokenizer.fit_on_texts(trainQues)

  # We add one because the Keras Tokenizer reserves index 0 and never uses it.
  vocabSize = len(tokenizer.wordIndex) + 1
  print(f'Vocab Size: {vocabSize}')
  print(tokenizer.wordIndex)


  print('\n--- Converting questions to bags of words...')
  train_X_seqs = tokenizer.texts_to_matrix(trainQues)
  test_X_seqs = tokenizer.texts_to_matrix(testQues)
  print(f'Example question bag of words: {train_X_seqs[0]}')


  print('\n--- Creating model input images...')
  train_X_Images = np.array([train_images[id] for id in train_image_ids])
  test_X_Images = np.array([test_images[id] for id in test_image_ids])


  print('\n--- Creating model outputs...')
  trainAnswerIndices = [allAnswers.index(a) for a in trainAnswers]
  testAnswerIndices = [allAnswers.index(a) for a in testAnswers]
  train_Y = to_categorical(trainAnswerIndices)
  test_Y = to_categorical(testAnswerIndices)
  print(f'Example model output: {train_Y[0]}')

  return (train_X_Images, train_X_seqs, train_Y, test_X_Images, test_X_seqs,
          test_Y, imShape, vocabSize, numAnswers,
          allAnswers, testQues, testAnswerIndices)  # for the analyze script

import sys
sys.argv=['']
del sys

#data prep, building multi modal system and training it 
from tensorflow.keras.callbacks import ModelCheckpoint
import argparse


# Support command-line options
parser = argparse.ArgumentParser()
parser.add_argument('--big-model', action='store_true', help='Use the bigger model with more conv layers')
parser.add_argument('--use-data-dir', action='store_true', help='Use custom data directory, at /data')
args = parser.parse_args()

if args.bigModel:
  print('Using big model')
if args.use_data_dir:
  print('Using data directory')

# Prepare data
train_X_Images, train_X_seqs, train_Y, test_X_Images, test_X_seqs, test_Y, imShape, vocabSize, numAnswers, _, _, _ = setup(args.use_data_dir)

print('\n--- Building model...')
model = buildModel(imShape, vocabSize, numAnswers, args.bigModel)
checkpoint = ModelCheckpoint('model.h5', save_best_only=True)

print('\n--- Training model...')
model.fit(
  [train_X_Images, train_X_seqs],
  train_Y,
  validation_data=([test_X_Images, test_X_seqs], test_Y),
  shuffle=True,
  epochs=8,
  callbacks=[checkpoint],
)

#softmax and obtaining outputs 
import argparse




# Support command-line options
parser = argparse.ArgumentParser()
parser.add_argument('--big-model', action='store_true')
parser.add_argument('--model-weights', help='model weights file', default='model.h5')
parser.add_argument('--use-data-dir', action='store_true', help='Use custom data directory, at /data')
args = parser.parse_args()
print('\n--- Calling train with bigModel: {}'.format(args.bigModel))
print('\n--- Model weights file: {}'.format(args.model_weights))

train_X_Images, train_X_seqs, train_Y, test_X_Images, test_X_seqs, test_Y, imShape, vocabSize, numAnswers, allAnswers, testQues, testAnswerIndices = setup(args.use_data_dir)

print('\n--- Building model...')
model = buildModel(imShape, vocabSize, numAnswers, args.bigModel)

model.load_weights(args.model_weights)
predictions = model.predict([test_X_Images, test_X_seqs])

# Stats for each answer
for ind in range(numAnswers):
	predValues = predictions[:, ind]
	answer = allAnswers[ind]
	print(f'\nStatistics for answer {ind}, {answer}')
	min = np.amin(predValues)
	max = np.amax(predValues)
	mean = np.mean(predValues)
	print(f'Min: {min}, Max: {max}, Mean: {mean}')

shapes = []
yesno = []
for i in range(numAnswers):
  if (allAnswers[i] == 'rectangle' or allAnswers[i] == 'circle' or allAnswers[i] == 'triangle'):
    shapes.append(i)
  elif allAnswers[i] == 'yes' or allAnswers[i] == 'no':
    yesno.append(i)

def return_class(answer):
  if answer in shapes:
    return 0
  if answer in yesno:
    return 1
  return 2
error_matrix = [[0 for _ in range(3)] for _ in range(3)]
total_errors = 0

color_error_matrix = [[0 for _ in range(numAnswers)] for _ in range(numAnswers)]
questions_wrong = {}

for ind in range(len(testAnswerIndices)):
  # answer numbers for triangle, circle, rectangle
  answer = testAnswerIndices[ind]
  pred = np.argmax(predictions[ind])
  if not answer == pred:
    total_errors += 1
    error_matrix[return_class(answer)][return_class(pred)] += 1
    color_error_matrix[answer][pred] += 1
    if (return_class(answer) == 1 and return_class(pred) == 1):
      if testQues[ind] in questions_wrong:
        questions_wrong[testQues[ind]] += 1
      else:
        questions_wrong[testQues[ind]] = 1

print('total error: {}'.format(total_errors / len(testAnswerIndices)))
print('Indexes are, in order, shapes, yes/no, colors')
print('Rows are class of answer, columns are class of prediction')
for i in range(3):
  print('{}\t{}\t{}\n'.format(error_matrix[i][0] / total_errors, error_matrix[i][1] / total_errors, error_matrix[i][2]/ total_errors))
print('-------------')
for i in range(numAnswers):
  to_print = ''
  for j in range(numAnswers):
    to_print += str(color_error_matrix[i][j]) + '\t'
  print(to_print)
print('-------------')
print(questions_wrong)

#Results are demonstrated with the help of a web app 

#https://apl405-termproject.netlify.app/
